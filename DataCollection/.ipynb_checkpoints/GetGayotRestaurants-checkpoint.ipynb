{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import fileinput\n",
    "from lxml import html  \n",
    "import unicodecsv as csv\n",
    "import requests\n",
    "#from exceptions import ValueError\n",
    "from time import sleep\n",
    "import re\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import quote, unquote\n",
    "import re, urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetParser(url):\n",
    "    response = requests.get(url).text\n",
    "    parser = html.fromstring(response)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BusinessInfoScrapper(parser):\n",
    "    raw_name = parser.xpath(\"//h1[contains(@class,'page-title')]//text()\")\n",
    "    raw_claimed = parser.xpath(\"//span[contains(@class,'claim-status_icon--claimed')]/parent::div/text()\")\n",
    "    raw_reviews = parser.xpath(\"//div[contains(@class,'biz-main-info')]//span[contains(@class,'review-count rating-qualifier')]//text()\")\n",
    "    raw_category  = parser.xpath('//div[contains(@class,\"biz-page-header\")]//span[@class=\"category-str-list\"]//a/text()')\n",
    "    hours_table = parser.xpath(\"//table[contains(@class,'hours-table')]//tr\")\n",
    "    details_table = parser.xpath(\"//div[@class='short-def-list']//dl\")\n",
    "    raw_map_link = parser.xpath(\"//a[@class='biz-map-directions']/img/@src\")\n",
    "    raw_phone = parser.xpath(\".//span[@class='biz-phone']//text()\")\n",
    "    raw_address = parser.xpath('//div[@class=\"mapbox-text\"]//div[contains(@class,\"map-box-address\")]//text()')\n",
    "    raw_wbsite_link = parser.xpath(\"//span[contains(@class,'biz-website')]/a/@href\")\n",
    "    raw_price_range = parser.xpath(\"//dd[contains(@class,'price-description')]//text()\")\n",
    "    raw_health_rating = parser.xpath(\"//dd[contains(@class,'health-score-description')]//text()\")\n",
    "    rating_histogram = parser.xpath(\"//table[contains(@class,'histogram')]//tr[contains(@class,'histogram_row')]\")\n",
    "    raw_ratings = parser.xpath(\"//div[contains(@class,'biz-page-header')]//div[contains(@class,'rating')]/@title\")\n",
    "    raw_neighborhood = parser.xpath(\"//div[@class='map-box-address u-space-l4']/span[@class='neighborhood-str-list']//text()\")\n",
    "    working_hours = []\n",
    "    \n",
    "    for hours in hours_table:\n",
    "        raw_day = hours.xpath(\".//th//text()\")\n",
    "        raw_timing = hours.xpath(\"./td//text()\")\n",
    "        day = ''.join(raw_day).strip()\n",
    "        timing = ''.join(raw_timing).strip()\n",
    "        working_hours.append({day:timing})\n",
    "    info = []\n",
    "    for details in details_table:\n",
    "        raw_description_key = details.xpath('.//dt//text()')\n",
    "        raw_description_value = details.xpath('.//dd//text()')\n",
    "        description_key = ''.join(raw_description_key).strip()\n",
    "        description_value = ''.join(raw_description_value).strip()\n",
    "        info.append({description_key:description_value})\n",
    "\n",
    "    ratings_histogram = [] \n",
    "    for ratings in rating_histogram:\n",
    "        raw_rating_key = ratings.xpath(\".//th//text()\")\n",
    "        raw_rating_value = ratings.xpath(\".//td[@class='histogram_count']//text()\")\n",
    "        rating_key = ''.join(raw_rating_key).strip()\n",
    "        rating_value = ''.join(raw_rating_value).strip()\n",
    "        ratings_histogram.append({int(rating_key[0]):int(rating_value)})\n",
    "\n",
    "    name = ''.join(raw_name).strip()\n",
    "    phone = ''.join(raw_phone).strip()\n",
    "    address = ' '.join(' '.join(raw_address).split())\n",
    "    health_rating = ''.join(raw_health_rating).strip()\n",
    "    price_range = ''.join(raw_price_range).strip()\n",
    "    claimed_status = ''.join(raw_claimed).strip()\n",
    "    category = ','.join(raw_category)\n",
    "    cleaned_ratings = ''.join(raw_ratings).strip()\n",
    "\n",
    "    if raw_wbsite_link:\n",
    "        #pass\n",
    "        decoded_raw_website_link = urllib.parse.unquote(raw_wbsite_link[0])\n",
    "        website = re.findall(\"biz_redir\\?url=(.*)&website_link\",decoded_raw_website_link)[0]\n",
    "    else:\n",
    "        website = ''\n",
    "\n",
    "    if raw_map_link:\n",
    "        decoded_map_url =  urllib.parse.unquote(raw_map_link[0])\n",
    "        map_coordinates = re.findall(\"([+-]?\\d+.\\d+,[+-]?\\d+\\.\\d+)\",decoded_map_url)[0].split(',')\n",
    "        latitude = float(map_coordinates[0])\n",
    "        longitude = float(map_coordinates[1])\n",
    "    else:\n",
    "        latitude = ''\n",
    "        longitude = ''\n",
    "\n",
    "    if raw_ratings:\n",
    "        ratings = float(re.findall(\"\\d+[.,]?\\d+\",cleaned_ratings)[0])\n",
    "    else:\n",
    "        ratings = 0\n",
    "\n",
    "    if raw_neighborhood:\n",
    "        neighborhood = ''.join(raw_neighborhood).strip()\n",
    "    else:\n",
    "        neighborhood = ''\n",
    "\n",
    "    if raw_reviews:\n",
    "        reviews = int(''.join(raw_reviews).strip().replace(' reviews','').replace(' review',''))\n",
    "    else:\n",
    "        reviews = ''\n",
    "    \n",
    "    data={'working_hours':working_hours,\n",
    "        'info':info,\n",
    "        'ratings_histogram':ratings_histogram,\n",
    "        'name':name,\n",
    "        'phone':phone,\n",
    "        'ratings':ratings,\n",
    "        'address':address,\n",
    "        'health_rating':health_rating,\n",
    "        'price_range':price_range,\n",
    "        'claimed_status':claimed_status,\n",
    "        'reviews':reviews,\n",
    "        'category':category,\n",
    "        'website':website,\n",
    "        'latitude':latitude,\n",
    "        'longitude':longitude,\n",
    "        'neighborhood': neighborhood,  \n",
    "        'url':url\n",
    "         }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetAllReivews(parser):\n",
    "    '''Given the parsed first webpage of a restaurant on yelp, return all reviews of that restaurants'''\n",
    "    review_dict = {'date': [], 'star': [], 'text': []}\n",
    "    \n",
    "    review_dates = parser.xpath(\"//div[@class='review-content']//span[@class='rating-qualifier']\")\n",
    "    for d in review_dates:\n",
    "        date = ''.join(d.xpath(\".//text()\")).strip().split('\\n')[0]\n",
    "        review_dict['date'].append(date)    \n",
    "\n",
    "    review_stars = parser.xpath(\"//div[@class='review review--with-sidebar']/div[@class='review-wrapper']/div[@class='review-content']/div[@class='biz-rating biz-rating-large clearfix']\")\n",
    "    for s in review_stars:\n",
    "        star = float(''.join(s.xpath(\".//@title\")).strip().replace(' star rating',''))\n",
    "        review_dict['star'].append(star)\n",
    "        \n",
    "    review_texts = parser.xpath(\"//div[@class='review review--with-sidebar']/div[@class='review-wrapper']/div[@class='review-content']/p\")\n",
    "    for t in review_texts:\n",
    "        text = ' '.join(t.xpath(\".//text()\"))\n",
    "        review_dict['text'].append(text)\n",
    "    \n",
    "    review = pd.DataFrame(review_dict)\n",
    "    review['date'] =  pd.to_datetime(review['date'])\n",
    "    \n",
    "    review_pages_section = parser.xpath(\"//div[@class='arrange arrange--stack arrange--baseline arrange--6']//text()\")     \n",
    "    review_pages = [item for item in [e.replace('\\n','').replace(' ','') for e in review_pages_section] if item != '' ]\n",
    "\n",
    "    if 'Next' not in review_pages:\n",
    "        return review\n",
    "    else:\n",
    "        nextpage = parser.xpath('//a[@class=\"u-decoration-none next pagination-links_anchor\"]/@href')[0]\n",
    "        nextparser = GetParser(nextpage)\n",
    "        sleep(1)\n",
    "        return review.append(GetAllReivews(nextparser), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurants = [line.strip() for line in open('gayot_list_nochain.txt')]\n",
    "yelp_url = 'https://www.yelp.com/biz/'\n",
    "# restaurants_dict = {\n",
    "#         'name':restaurants, \n",
    "#         'url':[], \n",
    "#         'working_hours':[],\n",
    "#         'info':[],\n",
    "#         'ratings_histogram':[],\n",
    "#         'ratings':[],\n",
    "#         'address':[],\n",
    "#         'health_rating':[],\n",
    "#         'price_range':[],\n",
    "#         'claimed_status':[],\n",
    "#         'reviews':[],\n",
    "#         'category':[],\n",
    "#         'latitude':[],\n",
    "#         'longitude':[],\n",
    "#         'neighborhood':[] }\n",
    "not_found = {'restaurants':[], 'url':[]}\n",
    "#restaurants_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restaurants_dict = {}\n",
    "offset = 203\n",
    "for i, r in enumerate(restaurants[offset:]):\n",
    "    keyword = r.lower().replace('\\'','').replace('&', 'and').replace(',','').replace(' ','-')\n",
    "    url = yelp_url + keyword + '-chicago'\n",
    "    #dict = {}\n",
    "    #restaurants_dict['url'].append(url)\n",
    "    response = requests.get(url)\n",
    "    sleep(1)\n",
    "    if response.status_code == 200:    \n",
    "        parsed = html.fromstring(response.text)\n",
    "        data = BusinessInfoScrapper(parsed)\n",
    "        #name = data['name']\n",
    "        restaurant = pd.DataFrame({k:[v] for k, v in data.items()})\n",
    "        restaurant.to_csv(str(i+offset)+'_'+keyword+'.csv', index=False)\n",
    "        # restaurants_dict['working_hours'].append(data['working_hours'])\n",
    "        # restaurants_dict['info'].append(data['info'])\n",
    "        # restaurants_dict['ratings_histogram'].append(data['ratings_histogram'])\n",
    "        # restaurants_dict['ratings'].append(data['ratings'])\n",
    "        # restaurants_dict['address'].append(data['address'])\n",
    "        # restaurants_dict['health_rating'].append(data['health_rating'])\n",
    "        # restaurants_dict['price_range'].append(data['price_range'])\n",
    "        # restaurants_dict['claimed_status'].append(data['claimed_status'])\n",
    "        # restaurants_dict['reviews'].append(data['reviews'])\n",
    "        # restaurants_dict['category'].append(data['category'])\n",
    "        # restaurants_dict['latitude'].append(data['latitude'])\n",
    "        # restaurants_dict['longitude'].append(data['longitude'])\n",
    "        # restaurants_dict['neighborhood'].append(data['neighborhood'])\n",
    "        reviews = GetAllReivews(parsed).sort_values(by='date', ascending=False).reset_index(drop=True)\n",
    "        reviews.to_csv(str(i+offset)+'_'+keyword+'_review.csv', index=False)        \n",
    "    else:\n",
    "        not_found['restaurants'].append(r)\n",
    "        not_found['url'].append(url)\n",
    "\n",
    "#restaurants_dict = {'resturants':restaurants, 'url':yelp_urls}\n",
    "#df_nf = pd.DataFrame(not_found)\n",
    "#df_nf.to_csv('RestaurantsNotFound.csv', index=False)\n",
    "#df = pd.DataFrame(restaurants_dict)\n",
    "#df.to_csv('Restaurants.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
