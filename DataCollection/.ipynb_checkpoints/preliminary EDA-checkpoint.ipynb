{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from canonical restaurant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CanonicalRestaurants.csv', 'CanonicalSummary.csv', 'ClosedRestaurants.csv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in listdir('./') if '.csv' in f]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./CanonicalRestaurants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'category', 'claimed_status', 'compound', 'date',\n",
       "       'first_review', 'health_rating', 'id', 'info', 'last_review',\n",
       "       'latitude', 'longitude', 'name', 'negative', 'neighborhood', 'neutral',\n",
       "       'permanently_closed', 'phone', 'positive', 'price_range', 'ratings',\n",
       "       'ratings_histogram', 'reviews', 'star', 'subjectivity', 'url',\n",
       "       'website', 'working_hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484650, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Claimed?'] = df['claimed_status'].apply(lambda x: 1 if str(x) == 'Claimed' else 0)\n",
    "df['HasWebsite'] = df['website'].apply(lambda x: 1 if 'http' in str(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplist = ['working_hours', 'health_rating', 'phone', 'url', 'claimed_status', \n",
    "            'website', 'address', 'longitude', 'latitude', 'reviews', \n",
    "            'date', 'star', 'subjectivity', 'negative', 'neutral', 'positive', 'compound']\n",
    "df.drop(droplist, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484609, 13)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['last_review'] != 'MISSING') & (df['first_review'] != 'MISSING')].copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 484609 entries, 0 to 484649\n",
      "Data columns (total 13 columns):\n",
      "category              484315 non-null object\n",
      "first_review          484609 non-null object\n",
      "id                    484609 non-null object\n",
      "info                  484609 non-null object\n",
      "last_review           484609 non-null object\n",
      "name                  484609 non-null object\n",
      "neighborhood          482772 non-null object\n",
      "permanently_closed    484609 non-null int64\n",
      "price_range           483514 non-null object\n",
      "ratings               484609 non-null float64\n",
      "ratings_histogram     484609 non-null object\n",
      "Claimed?              484609 non-null int64\n",
      "HasWebsite            484609 non-null int64\n",
      "dtypes: float64(1), int64(3), object(9)\n",
      "memory usage: 51.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['date'] =  pd.to_datetime(df['date'])\n",
    "df['last_review'] =  pd.to_datetime(df['last_review'])\n",
    "df['first_review'] =  pd.to_datetime(df['first_review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove closed restaurants that have last review earlier than 2012/01/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "cut_day = datetime.date(2012, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = (df['permanently_closed'] == 1) & (df['last_review'] < cut_day)\n",
    "cut_df = df[~mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>first_review</th>\n",
       "      <th>id</th>\n",
       "      <th>info</th>\n",
       "      <th>last_review</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>permanently_closed</th>\n",
       "      <th>price_range</th>\n",
       "      <th>ratings</th>\n",
       "      <th>ratings_histogram</th>\n",
       "      <th>Claimed?</th>\n",
       "      <th>HasWebsite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breakfast &amp; Brunch,American (Traditional)</td>\n",
       "      <td>2011-10-08</td>\n",
       "      <td>0_2-sparrows</td>\n",
       "      <td>[{'Takes Reservations': 'No'}, {'Delivery': 'N...</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>2 Sparrows</td>\n",
       "      <td>Lincoln Park</td>\n",
       "      <td>1</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{5: 63}, {4: 94}, {3: 67}, {2: 78}, {1: 34}]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breakfast &amp; Brunch,American (Traditional)</td>\n",
       "      <td>2011-10-08</td>\n",
       "      <td>0_2-sparrows</td>\n",
       "      <td>[{'Takes Reservations': 'No'}, {'Delivery': 'N...</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>2 Sparrows</td>\n",
       "      <td>Lincoln Park</td>\n",
       "      <td>1</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{5: 63}, {4: 94}, {3: 67}, {2: 78}, {1: 34}]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Breakfast &amp; Brunch,American (Traditional)</td>\n",
       "      <td>2011-10-08</td>\n",
       "      <td>0_2-sparrows</td>\n",
       "      <td>[{'Takes Reservations': 'No'}, {'Delivery': 'N...</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>2 Sparrows</td>\n",
       "      <td>Lincoln Park</td>\n",
       "      <td>1</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{5: 63}, {4: 94}, {3: 67}, {2: 78}, {1: 34}]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Breakfast &amp; Brunch,American (Traditional)</td>\n",
       "      <td>2011-10-08</td>\n",
       "      <td>0_2-sparrows</td>\n",
       "      <td>[{'Takes Reservations': 'No'}, {'Delivery': 'N...</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>2 Sparrows</td>\n",
       "      <td>Lincoln Park</td>\n",
       "      <td>1</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{5: 63}, {4: 94}, {3: 67}, {2: 78}, {1: 34}]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breakfast &amp; Brunch,American (Traditional)</td>\n",
       "      <td>2011-10-08</td>\n",
       "      <td>0_2-sparrows</td>\n",
       "      <td>[{'Takes Reservations': 'No'}, {'Delivery': 'N...</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>2 Sparrows</td>\n",
       "      <td>Lincoln Park</td>\n",
       "      <td>1</td>\n",
       "      <td>$11-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{5: 63}, {4: 94}, {3: 67}, {2: 78}, {1: 34}]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    category first_review            id  \\\n",
       "0  Breakfast & Brunch,American (Traditional)   2011-10-08  0_2-sparrows   \n",
       "1  Breakfast & Brunch,American (Traditional)   2011-10-08  0_2-sparrows   \n",
       "2  Breakfast & Brunch,American (Traditional)   2011-10-08  0_2-sparrows   \n",
       "3  Breakfast & Brunch,American (Traditional)   2011-10-08  0_2-sparrows   \n",
       "4  Breakfast & Brunch,American (Traditional)   2011-10-08  0_2-sparrows   \n",
       "\n",
       "                                                info last_review        name  \\\n",
       "0  [{'Takes Reservations': 'No'}, {'Delivery': 'N...  2015-02-02  2 Sparrows   \n",
       "1  [{'Takes Reservations': 'No'}, {'Delivery': 'N...  2015-02-02  2 Sparrows   \n",
       "2  [{'Takes Reservations': 'No'}, {'Delivery': 'N...  2015-02-02  2 Sparrows   \n",
       "3  [{'Takes Reservations': 'No'}, {'Delivery': 'N...  2015-02-02  2 Sparrows   \n",
       "4  [{'Takes Reservations': 'No'}, {'Delivery': 'N...  2015-02-02  2 Sparrows   \n",
       "\n",
       "   neighborhood  permanently_closed price_range  ratings  \\\n",
       "0  Lincoln Park                   1      $11-30      3.0   \n",
       "1  Lincoln Park                   1      $11-30      3.0   \n",
       "2  Lincoln Park                   1      $11-30      3.0   \n",
       "3  Lincoln Park                   1      $11-30      3.0   \n",
       "4  Lincoln Park                   1      $11-30      3.0   \n",
       "\n",
       "                               ratings_histogram  Claimed?  HasWebsite  \n",
       "0  [{5: 63}, {4: 94}, {3: 67}, {2: 78}, {1: 34}]         1           1  \n",
       "1  [{5: 63}, {4: 94}, {3: 67}, {2: 78}, {1: 34}]         1           1  \n",
       "2  [{5: 63}, {4: 94}, {3: 67}, {2: 78}, {1: 34}]         1           1  \n",
       "3  [{5: 63}, {4: 94}, {3: 67}, {2: 78}, {1: 34}]         1           1  \n",
       "4  [{5: 63}, {4: 94}, {3: 67}, {2: 78}, {1: 34}]         1           1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476583, 13)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapse the cononical data to one restaurant per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 13)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_df.drop_duplicates(inplace=True)\n",
    "cut_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    849\n",
       "1    303\n",
       "Name: permanently_closed, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_df['permanently_closed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1152 entries, 0 to 484577\n",
      "Data columns (total 13 columns):\n",
      "category              1150 non-null object\n",
      "first_review          1152 non-null datetime64[ns]\n",
      "id                    1152 non-null object\n",
      "info                  1152 non-null object\n",
      "last_review           1152 non-null datetime64[ns]\n",
      "name                  1152 non-null object\n",
      "neighborhood          1141 non-null object\n",
      "permanently_closed    1152 non-null int64\n",
      "price_range           1127 non-null object\n",
      "ratings               1152 non-null float64\n",
      "ratings_histogram     1152 non-null object\n",
      "Claimed?              1152 non-null int64\n",
      "HasWebsite            1152 non-null int64\n",
      "dtypes: datetime64[ns](2), float64(1), int64(3), object(7)\n",
      "memory usage: 126.0+ KB\n"
     ]
    }
   ],
   "source": [
    "cut_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "closed = cut_df[cut_df['permanently_closed'] == 1].copy()\n",
    "opened = cut_df[cut_df['permanently_closed'] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$11-30         167\n",
       "$31-60          76\n",
       "Under $10       23\n",
       "Above $61       12\n",
       "Moderate        11\n",
       "Inexpensive      4\n",
       "Pricey           2\n",
       "Name: price_range, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed['price_range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_train_list = list(id_train['id'])\n",
    "id_test_list = list(id_test['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to extract NLP data with varying block weeks and open weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetReviewSummary(df=None, blockweeks=52, openweeks=52, NLPsummary=['star']):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from datetime import timedelta\n",
    "    Dict = {}\n",
    "    df = df.copy()\n",
    "    df['date'] =  pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].apply(lambda x: x.year)\n",
    "    blck = timedelta(weeks=blockweeks)\n",
    "    blocktime = df['date'].iloc[0] - blck\n",
    "    new_df = df[df['date'] <= blocktime].copy()\n",
    "    Dict['avg_reviews'] = [float(new_df.shape[0])/(new_df['year'].max() - new_df['year'].min() + 1)]    \n",
    "    Dict['avg_star'] = new_df['star'].mean()\n",
    "    Dict['5_star'] = new_df[new_df['star'] == 5.0].shape[0]\n",
    "    Dict['4_star'] = new_df[new_df['star'] == 4.0].shape[0]\n",
    "    Dict['3_star'] = new_df[new_df['star'] == 3.0].shape[0]\n",
    "    Dict['2_star'] = new_df[new_df['star'] == 2.0].shape[0]\n",
    "    Dict['1_star'] = new_df[new_df['star'] == 1.0].shape[0]\n",
    "    if NLPsummary != None:            \n",
    "        opn = timedelta(weeks=openweeks)        \n",
    "        opentime = blocktime - opn\n",
    "        open_df = new_df[(new_df['date'] >= opentime)].copy()\n",
    "        open_df['days'] = open_df['date'].apply(lambda x: (x - list(open_df['date'])[-1]).days)\n",
    "        for item in NLPsummary:\n",
    "            Dict['AvgLast_'+item] = [open_df[item].mean()]\n",
    "            if open_df.shape[0] >= 2:             \n",
    "                lr = LinearRegression()\n",
    "                lr.fit(open_df[['days']],open_df[item])\n",
    "                Dict['Last_'+item+'_intrcpt'] = [lr.intercept_]\n",
    "                Dict['Last_'+item+'_coef'] = [lr.coef_[0]]\n",
    "            else:\n",
    "                Dict['Last_'+item+'_intrcpt'] = [open_df[item].mean()]\n",
    "                Dict['Last_'+item+'_coef'] = [0.0] \n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetEachSummary(df=None, idname=None, blockweeks=52, openweeks=52, NLPsummary=['star','compound','subjectivity']):\n",
    "    subset = df[df['id']==idname]\n",
    "    row = pd.DataFrame(subset.iloc[0,:]).transpose()\n",
    "    InfoList = ['id', 'name', 'category', 'price_range', 'neighborhood', 'info', 'Claimed?', \n",
    "                'HasWebsite', 'first_review', 'last_review', 'permanently_closed']\n",
    "    Info = row[InfoList]\n",
    "    ReviewList = ['date', 'star', 'compound', 'neutral', 'positive', 'negative', 'subjectivity']\n",
    "    Review = subset[ReviewList]\n",
    "    Summary = GetReviewSummary(df=Review, blockweeks=blockweeks, openweeks=openweeks, NLPsummary=NLPsummary)\n",
    "    Sum_df = pd.DataFrame(Summary, index=[Info.index[0]])\n",
    "    each = Info.join(Sum_df)\n",
    "    return each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetSummarydf(df=None, idlist=None, blockweeks=52, openweeks=52, NLPsummary=['star','compound','subjectivity']):\n",
    "    Summary_df = GetEachSummary(df=df, idname=idlist[0], \n",
    "                                blockweeks=blockweeks, openweeks=openweeks, NLPsummary=NLPsummary)\n",
    "    for i, idname in enumerate(idlist[1:]):\n",
    "        new = GetEachSummary(df=df, idname=idname, \n",
    "                             blockweeks=blockweeks, openweeks=openweeks, NLPsummary=NLPsummary)\n",
    "        Summary_df = Summary_df.append(new, ignore_index=True)     \n",
    "    return Summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dictionaries to store train/test dataframes of different block/open weeks combinations\n",
    "- block weeks: 13, 26, 52 weeks\n",
    "- open weeks: 26, 52, 78 weeks\n",
    "- 9 combinations in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_block13_open26\n",
      "df_block13_open52\n",
      "df_block13_open78\n",
      "df_block26_open26\n",
      "df_block26_open52\n",
      "df_block26_open78\n",
      "df_block52_open26\n",
      "df_block52_open52\n",
      "df_block52_open78\n"
     ]
    }
   ],
   "source": [
    "blck = [13, 26, 52]\n",
    "opn = [26, 52, 78]\n",
    "train = {} \n",
    "test = {}\n",
    "for b in blck:\n",
    "    for o in opn:\n",
    "        key = 'df_block' + str(b) + '_open' + str(o)\n",
    "        print(key)\n",
    "        train[key] = GetSummarydf(df=cut_df, idlist=id_train_list, \n",
    "                                  blockweeks=b, openweeks=o, NLPsummary=['star','compound','subjectivity'])\n",
    "        test[key] = GetSummarydf(df=cut_df, idlist=id_test_list, \n",
    "                                 blockweeks=b, openweeks=o, NLPsummary=['star','compound','subjectivity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat lists of dummy variables for category, neighborhood, and price range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetLabels(df=train['df_block13_open26'], column='category'):\n",
    "    ensumble = []\n",
    "    for line in df[column]:\n",
    "        if type(line) != float:\n",
    "            labels = line.split(',')\n",
    "            for l in labels:\n",
    "                l = l.strip()\n",
    "                if l not in ensumble:\n",
    "                    ensumble.append(l)\n",
    "    return ensumble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['French',\n",
       " 'Barbeque',\n",
       " 'Music Venues',\n",
       " 'Pizza',\n",
       " 'Italian',\n",
       " 'Middle Eastern',\n",
       " 'Vegetarian',\n",
       " 'Falafel',\n",
       " 'Bakeries',\n",
       " 'Breakfast & Brunch',\n",
       " 'Ukrainian',\n",
       " 'American (New)',\n",
       " 'Southern',\n",
       " 'Cocktail Bars',\n",
       " 'American (Traditional)',\n",
       " 'Sandwiches',\n",
       " 'Burgers',\n",
       " 'Restaurants',\n",
       " 'Bars',\n",
       " 'Coffee & Tea',\n",
       " 'Pubs',\n",
       " 'Hot Dogs',\n",
       " 'Thai',\n",
       " 'Japanese',\n",
       " 'Chinese',\n",
       " 'Sushi Bars',\n",
       " 'Mexican',\n",
       " 'Cuban',\n",
       " 'Indian',\n",
       " 'Pakistani',\n",
       " 'Ethiopian',\n",
       " 'Cafes',\n",
       " 'Juice Bars & Smoothies',\n",
       " 'Desserts',\n",
       " 'Irish',\n",
       " 'Latin American',\n",
       " 'Korean',\n",
       " 'Asian Fusion',\n",
       " 'Grocery',\n",
       " 'Venues & Event Spaces',\n",
       " 'Tapas Bars',\n",
       " 'Spanish',\n",
       " 'Tapas/Small Plates',\n",
       " 'Shanghainese',\n",
       " 'Cantonese',\n",
       " 'Wine Bars',\n",
       " 'Steakhouses',\n",
       " 'Beer Bar',\n",
       " 'Austrian',\n",
       " 'Salad',\n",
       " 'Argentine',\n",
       " 'Greek',\n",
       " 'British',\n",
       " 'Gastropubs',\n",
       " 'Modern European',\n",
       " 'Fast Food',\n",
       " 'Dance Clubs',\n",
       " 'Comfort Food',\n",
       " 'Himalayan/Nepalese',\n",
       " 'Soup',\n",
       " 'Diners',\n",
       " 'Lounges',\n",
       " 'Food Stands',\n",
       " 'Jazz & Blues',\n",
       " 'Noodles',\n",
       " 'Fondue',\n",
       " 'Mediterranean',\n",
       " 'Gluten-Free',\n",
       " 'Colombian',\n",
       " 'Seafood',\n",
       " 'Brazilian',\n",
       " 'Chicken Wings',\n",
       " 'Sports Bars',\n",
       " 'Hawaiian',\n",
       " 'Ice Cream & Frozen Yogurt',\n",
       " 'Cooking Schools',\n",
       " 'Vietnamese',\n",
       " 'Polish',\n",
       " 'Food Trucks',\n",
       " 'Chicken Shop',\n",
       " 'Dive Bars',\n",
       " 'Cajun/Creole',\n",
       " 'Russian',\n",
       " 'Creperies',\n",
       " 'Fish & Chips',\n",
       " 'Caterers',\n",
       " 'Indonesian',\n",
       " 'Vegan',\n",
       " 'German',\n",
       " 'Turkish',\n",
       " 'Filipino',\n",
       " 'Beer',\n",
       " 'Wine & Spirits',\n",
       " 'Ramen',\n",
       " 'Basque',\n",
       " 'Moroccan',\n",
       " 'Delis',\n",
       " 'Karaoke',\n",
       " 'Tex-Mex',\n",
       " 'Chocolatiers & Shops',\n",
       " 'Buffets',\n",
       " 'Halal',\n",
       " 'Beer Gardens',\n",
       " 'Irish Pub',\n",
       " 'Bagels',\n",
       " 'Champagne Bars',\n",
       " 'Puerto Rican',\n",
       " 'Persian/Iranian',\n",
       " 'Dim Sum',\n",
       " 'Soul Food',\n",
       " 'African',\n",
       " 'Adult Entertainment',\n",
       " 'Meat Shops',\n",
       " 'Scandinavian',\n",
       " 'Bubble Tea',\n",
       " 'Butcher',\n",
       " 'Donuts',\n",
       " 'Szechuan',\n",
       " 'Pool Halls',\n",
       " 'Breweries',\n",
       " 'Peruvian',\n",
       " 'Caribbean',\n",
       " 'Pasta Shops',\n",
       " 'Toy Stores',\n",
       " 'Scottish',\n",
       " 'Live/Raw Food',\n",
       " 'Afghan']"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = GetLabels(df=train['df_block13_open26'], column='category')\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Edgewater',\n",
       " 'West Town',\n",
       " 'Wicker Park',\n",
       " 'Lincoln Park',\n",
       " 'Andersonville',\n",
       " 'Humboldt Park',\n",
       " 'Near West Side',\n",
       " 'West Loop',\n",
       " 'Noble Square',\n",
       " 'Lakeview',\n",
       " 'Bucktown',\n",
       " 'University Village',\n",
       " 'South Loop',\n",
       " 'Near North Side',\n",
       " 'DePaul',\n",
       " 'Irving Park',\n",
       " 'Logan Square',\n",
       " 'Roscoe Village',\n",
       " 'Avondale',\n",
       " 'Greektown',\n",
       " 'North Center',\n",
       " 'Bridgeport',\n",
       " 'Old Town',\n",
       " 'Portage Park',\n",
       " 'Chinatown',\n",
       " 'Uptown',\n",
       " 'Albany Park',\n",
       " 'Rogers Park',\n",
       " 'Garfield Ridge',\n",
       " 'Fulton Market',\n",
       " 'Pilsen',\n",
       " 'Edison Park',\n",
       " 'River North',\n",
       " 'Streeterville',\n",
       " 'Ukrainian Village',\n",
       " 'Ravenswood',\n",
       " 'Lincoln Square',\n",
       " 'River East',\n",
       " 'The Loop',\n",
       " 'River West',\n",
       " 'West Rogers Park',\n",
       " 'Cragin',\n",
       " 'Gold Coast',\n",
       " 'Near Southside',\n",
       " 'Wrigleyville',\n",
       " 'West Lawn',\n",
       " 'Hermosa',\n",
       " 'Little Village',\n",
       " \"Printer's Row\",\n",
       " 'North Park',\n",
       " 'Forest Glen']"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhoods = GetLabels(df=train['df_block13_open26'], column='neighborhood')\n",
    "neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$11-30',\n",
       " 'Under $10',\n",
       " '$31-60',\n",
       " 'Moderate',\n",
       " 'Inexpensive',\n",
       " 'Pricey',\n",
       " 'Above $61']"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_ranges = GetLabels(df=train['df_block13_open26'], column='price_range')\n",
    "price_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop 'Restaurant', 'Pilsen', and 'Pricey' for category, neighborhood, and price range, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories.remove('Restaurants')\n",
    "neighborhoods.remove('Pilsen')\n",
    "#price_ranges.remove('Pricey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check values for 'Attire', 'Parking', 'Alcohol', 'Noise Level', and 'Wi-Fi' in info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ColumnParser(info, text=False):\n",
    "    '''Parse info column to a dictionary'''\n",
    "    import re\n",
    "    Dict = {}\n",
    "    if len(info) > 2:\n",
    "        List = re.findall(r\"\\{(.*?)\\}\", info)        \n",
    "        for item in List:  \n",
    "            if text:\n",
    "                key = re.findall(r\"\\'(.*?)\\'\", item)[0]\n",
    "                value = re.findall(r\"\\'(.*?)\\'\", item)[1]\n",
    "            else:\n",
    "                key = item.split(': ')[0]\n",
    "                value = item.split(': ')[1]\n",
    "            Dict[key] = value\n",
    "    return Dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = train['df_block13_open26'].copy()\n",
    "df['info'] = df['info'].apply(lambda x: ColumnParser(x, text=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetValues(df=train['df_block13_open26'], feature='Attire'):\n",
    "    ensumble = []\n",
    "    for item in list(df['info']):\n",
    "        if feature in item.keys():\n",
    "            if ', ' in item[feature]:\n",
    "                for i in item[feature].split(', '):\n",
    "                    ensumble.append(i)\n",
    "            else:\n",
    "                ensumble.append(item[feature])\n",
    "    return list(set(ensumble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attire:  ['Dressy', 'Formal (Jacket Required)', 'Casual']\n",
      "Parking:  ['Garage', 'Street', 'Valet', 'Validated', 'Private Lot']\n",
      "Alcohol:  ['Full Bar', 'No', 'Beer & Wine Only']\n",
      "Noise Level:  ['Loud', 'Very Loud', 'Quiet', 'Average']\n",
      "Wi-Fi:  ['No', 'Paid', 'Free']\n"
     ]
    }
   ],
   "source": [
    "for f in ['Attire', 'Parking', 'Alcohol', 'Noise Level', 'Wi-Fi']:\n",
    "    print(f+': ', GetValues(df=df, feature=f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binomial = ['Accepts Credit Cards', 'Good for Groups', 'Good for Kids', \n",
    "                'Takes Reservations', 'Outdoor Seating', 'Take-out',  'Delivery', 'Has TV']\n",
    "polynomial = {'Attire': ['Dressy', 'Casual'],\n",
    "              'Parking': ['Valet', 'Garage', 'Street', 'Validated'], \n",
    "              'Alcohol': ['Full Bar', 'No'], \n",
    "              'Noise Level': ['Loud', 'Quite', 'Average'],\n",
    "              'Wi-Fi': ['No', 'Free']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_copy = {}\n",
    "test_copy = {}\n",
    "for key, df in train.items():\n",
    "    train_copy[key] = df.copy()\n",
    "for key, df in test.items():\n",
    "    test_copy[key] = df.copy()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process each train/test pair to get dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(list(train_copy.values()) + list(test_copy.values())):\n",
    "    print(i)\n",
    "    for key, columns in {'category': categories, 'neighborhood': neighborhoods, 'price_range': price_ranges}.items():\n",
    "        for c in columns:\n",
    "            df[c] = df[key].apply(lambda x: 1 if c in str(x) else 0)\n",
    "    df['info'] = df['info'].apply(lambda x: ColumnParser(x, text=True))\n",
    "    for b in binomial:\n",
    "        df[b] = df['info'].apply(lambda x: 1 if x.get(b,'0') == 'Yes' else 0)\n",
    "    for k, values in polynomial.items():\n",
    "        for v in values:\n",
    "            df[k+'_'+v] = df['info'].apply(lambda x: 1 if x.get(k, '0') == v else 0 )\n",
    "    df.drop(['category', 'neighborhood', 'price_range', 'info'], inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write each train/test dataframe as csv files in ../part_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, df in train_copy.items():\n",
    "    df.to_csv('../part_03/train_'+key+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, df in test_copy.items():\n",
    "    df.to_csv('../part_03/test_'+key+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
